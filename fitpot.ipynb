{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77ac8cba783beb33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Gaussian Process regression for fitting interatomic potentials\n",
    "\n",
    "## Workshop Aims\n",
    "* Data representation using invariant descriptors\n",
    "* Building covariance matrices for derived quantities - learning from total energy data\n",
    "* Uncertainty analysis of predicted energy values\n",
    "* Optimising hyperparameters\n",
    "* Relaxing geometry using a machine learned potential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0925ca393e319102",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GPy\n",
    "\n",
    "from ase.io import read\n",
    "import nglview\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da1e48df809e6488",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9ebcb163bda0b66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1\n",
    "### Learning the interaction energy of a single water molecule\n",
    "\n",
    "The quantum mechanical energy of a water molecule - within the Born-Oppenheimer approximation - is a function of the geometry of the molecule, i.e. the Cartesian coordinates $\\mathbf{r}_\\rm{O}$, $\\mathbf{r}_{\\rm H_1}$ and  $\\mathbf{r}_{\\rm H_2}$. Of course, this energy does not depend on the orientation of the water molecule if there is no external field interacting with the molecule.\n",
    "\n",
    "<img src=\"water.png\">\n",
    "\n",
    "We can rewrite the energy function as $E(\\mathbf{r}_{\\rm O},\\mathbf{r}_{\\rm H_1},\\mathbf{r}_{\\rm H_2}) \\equiv E(r_{\\rm OH_1},r_{\\rm OH_2},\\theta_{\\rm HOH})$ where $r_{\\rm OH}$ are the bond lengths and $\\theta_{\\rm HOH}$ the bond angle. This description is invariant to rotations and translations. We also know that the 'label' of the hydrogens is unimportant (i.e. swapping $\\rm H_1$ and $\\rm H_2$ does not change the energy), therefore it is useful to symmetrise the distances.\n",
    "\n",
    "In this exercise, we will use the following data coordinates:\n",
    "* $r_+ = r_{\\rm OH_1} + r_{\\rm OH_2}$\n",
    "* $r_- = (r_{\\rm OH_1} - r_{\\rm OH_2})^2$\n",
    "* $a = \\mathbf{r}_{\\rm OH_1} \\cdot \\mathbf{r}_{\\rm OH_2}$\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Explain why the descriptor functions $r_+$, $r_-$ and $a$ are invariant to rigid rotations, translations of the molecule and permutations of the hydrogen indices.** [5 marks]\n",
    "\n",
    "**Hint:** For each descriptor element, consider how they change if a rigid geometrical transformation is applied which changes the Cartesian coordinates, but keeps the molecular geometry intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e72aabac931c9823",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in water configurations\n",
    "water_configs = read(\"water_configs.xyz\", format=\"extxyz\", index=\":\")\n",
    "# There should be 2886 independent water molecules\n",
    "print(len(water_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - for visualisation\n",
    "nglview.show_asetraj(water_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [] # input features\n",
    "y = [] # target values\n",
    "\n",
    "# Calculate descriptor vectors for each molecule and collect target energies\n",
    "for a in water_configs:\n",
    "    p = a.get_positions() # positions: O, H1, H2\n",
    "    rOH1 = # calculate distance OH1, use a.get_distance()\n",
    "    rOH2 = # calculate distances OH2\n",
    "    aHOH = # dot product between the vectors OH1 and OH2, e.g p[1]-p[0]\n",
    "    \n",
    "    x.append([(rOH1 + rOH2), (rOH1 - rOH2)**2, aHOH]) # collect descriptor vectors\n",
    "    \n",
    "    y.append(a.get_potential_energy()) # QM energy of a water molecule    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2265a8aeb3698090",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We randomly split the data to a train and test set and then use it to train a Gaussian process regression model using `GPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size sets the fraction of the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.9) \n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)[:, None] # GPy needs a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim: dimensionality of data points - our descriptor vectors have three elements\n",
    "# variance: range (squared) of the function\n",
    "print(\"Range of input data: {:.2f}\".format(y_train.max()-y_train.min()))\n",
    "# lengthscale: characteristic lengthscale - start with a default of 0.5\n",
    "# ARD: automatic relevance determination - allows separate lengthscales for each three descriptor dimensions\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=3, variance=1., lengthscale=10.,ARD=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f7ef19e25d32937",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2.a\n",
    "\n",
    "**Why is it useful to use 'automatic relevance determination' (separate lengthscales, rather than one for all three dimensions) in this situation?** [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-66c4ed6940a7f439",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Gaussian Process model by adding training data. Start with a small noise parameter.\n",
    "m = GPy.models.GPRegression(X_train, y_train, kernel, noise_var=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise the likelihood with respect of the hyperparameters of the model\n",
    "m.optimize_restarts(num_restarts = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9b8e88c2e4d1842e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2.b\n",
    "\n",
    "**When optimising the hyperparameters, what do we mean by restarts and why is it useful to do more than one?** [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1fc45652a8ca50ee",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result of the likelihood optimisation\n",
    "display(m)\n",
    "m.rbf.lengthscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-727aaa09cfd54578",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`m` contains the trained model: a combination of the _prior_ (in the form of the kernel and its hyperparameters, as well as the noise model) and _data_ (in the form of geometrical descriptors and corresponding energy values).\n",
    "\n",
    "### Question 2.c\n",
    "\n",
    "**From the output of the previous cell, what is the noise variance of the optimal model? What does this tell us about the data?** [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5333023354b78801",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the energy of water configurations.\n",
    "\n",
    "y_train_predict, y_train_error = m.predict(np.array(X_train)) # predict energies of training configurations\n",
    "y_test_predict, y_test_error =   # predict energies of the test set configurations\n",
    "\n",
    "# root-mean-square error (RMSE)\n",
    "rmse =  \n",
    "print(\"RMSE = {:.3f} eV\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Question 2.d\n",
    "\n",
    "**Plot graphs to show the correlation of actual and predicted energies, and of the actual and predicted error** [5 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-bff3d60b9fc1fa85",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the correlation of actual and predicted data\n",
    "plt.plot(y_train,y_train_predict,\"s\", label='Train')\n",
    "plt.errorbar(y_test,y_test_predict,yerr=np.sqrt(y_test_error[:,0]),fmt=\".\", label='Test')\n",
    "plt.xlabel('True energies / eV')\n",
    "plt.ylabel('Predicted energies / eV')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the correlation of actual and predicted error\n",
    "plt.plot()\n",
    "plt.xlabel('True error / eV')\n",
    "plt.ylabel('Predicted error / eV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8987a36072a90b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3.a\n",
    "\n",
    "**Briefly disucss how accurate the Gaussian Process water model is. How accurate is the error prediction?** [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ca0013e2d181a889",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e26ca6bc0eb19d40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3.b\n",
    "\n",
    "We only used 10% of the data for training. By adapting the code above, starting from where we split the data into test and train set, fit further GP models with different fractions (10%, 20%, 40%, 80%) of training data - don't forget to optimise the likelihood. Summarise in a table how the root mean squared error (RMSE) changes. Write a short paragraph about the advantages and disadvantages of using more training data. [5 marks code + 5 marks discussion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c11793666609373f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['train_size', 'RMSE'])\n",
    "\n",
    "df['train_size'] = [0.1, 0.2, 0.4, 0.8]\n",
    "\n",
    "for i, train_size in enumerate(df.train_size):\n",
    "    # split data \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)[:, None]\n",
    "    # create modeel \n",
    "    # optimise\n",
    "    # predict on test set y_test_predict, y_test_error = \n",
    "    rmse = \n",
    "    print(train_size, rmse)\n",
    "    df.iloc[i, 1] = rmse\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-23dadcbd2f915dae",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10b8cc67f26c5c71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Optimising the geometry of the water molecule, using a Gaussian Process energy model\n",
    "In the following exercise, we will relax the Cartesian coordinates of a water molecule, in order to find the equilibrium geometry. We will use a wrapper function that generates the symmetrised descriptors and using the GP model, predicts the energy of the water molecule. For simplicity, we use the Nelder-Mead algorithm to find the minimum of the function, as it does not require access to the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the wrapper function: Cartesian coordinates -> symmetrised descriptors -> GP\n",
    "def GP_water_energy(x):\n",
    "    _x = np.reshape(x, (3,3)) # Input is a flat array of x,y,z coordinates of three atoms.\n",
    "    r1 = np.linalg.norm(_x[0] - _x[1]) # rOH1\n",
    "    r2 = np.linalg.norm(_x[0] - _x[2]) # rOH2\n",
    "    a = np.dot(_x[0] - _x[1], \n",
    "               _x[0] - _x[2]) # dot product of the two OH vectors\n",
    "    _xx = np.array([[(r1 + r2),\n",
    "                     (r1 - r2)**2, \n",
    "                     a]]) # symmetrised descriptor (see above)\n",
    "    res = m.predict(_xx)[0][0][0] # GP prediction\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7cfd75ac56214a9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We start from a not-too crazy initial condition, and relax the position of all atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "x0 = np.array([0,0,0,       # Oxygen atom\n",
    "               1.2,0,0,     # 1st hydrogen atom\n",
    "               -0.5,0.7,0]) # 2nd hydrogen atom\n",
    "\n",
    "res = minimize(GP_water_energy, # function to minimise\n",
    "               x0,              # initial condition\n",
    "               method='nelder-mead',\n",
    "               options={\"maxiter\":1000, # number of iterations in the minimiser\n",
    "                        \"fatol\":1e-6    # stopping criterion (tolerance)\n",
    "                       })\n",
    "# res.x contains the final configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform the Cartesian coordinates into bond lengths and the bond angle, \n",
    "# for easier interpretation\n",
    "\n",
    "_x = np.reshape(res.x, (3, 3))\n",
    "r1 = \n",
    "r2 = \n",
    "a = \n",
    "print(\"r1 = {:.3f} A\\nr2 = {:.3f} A\\nangle = {:.1f} degrees\".format(r1,r2,np.rad2deg(np.arccos(a))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ae4a2b03b04c71c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "**Inspect the resulting water geometry. How realistic is it? Compare the geometrical parameters to literature (experimental and/or theoretical) values.** [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d9b24bcfc83519b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42c1756da9bd0e5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Extension question (not assessed)\n",
    "Try different kernels `GPy.kern.` in the Gaussian Process regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d82eaef8b9dc228d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eeaf2b2a8e5170b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2\n",
    "### Inferring a pair interaction model based on total energy information\n",
    "\n",
    "For certain types of atomic systems, the total, inherently many-body interaction energy may be approximated by pair interaction terms: $E(\\mathbf{r}_1, \\mathbf{r}_2, \\ldots \\mathbf{r}_N) \\approx \\sum^N_{i<j} E_2(r_{ij})$, where the system consists of $N$ atoms with Cartesian coordinates $\\mathbf{r}_1, \\mathbf{r}_2, \\ldots \\mathbf{r}_N$. $E_2$ is a function of interatomic distances $r_{ij}$. Example where this works well are noble gases or certain types of metals.\n",
    "\n",
    "In this part of the workshop, we will study a toy problem, where the total interaction energy consists explicitly of two-body terms, and the aim of the workshop is to recover the original model. We will use configurations of clusters of 12-19 atoms, and the interaction energy (the underlying function we are trying to fit) will be the Lennard-Jones model for the total energy\n",
    "\n",
    "$$\n",
    "E_2^{LJ}(r_{ij}) = 4\\left(\\frac1{r_{ij}^{12}} - \\frac1{r_{ij}^6} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the cluster configurations\n",
    "cluster_trajectory = read(\"clusters.xyz\", index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "nglview.show_asetraj(cluster_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, we calculate the total energy and collect it in cluster_energy\n",
    "from ase.calculators.lj import LennardJones\n",
    "p = LennardJones()\n",
    "\n",
    "cluster_energy = []\n",
    "for a in cluster_trajectory:\n",
    "    a.set_calculator(p)\n",
    "    cluster_energy.append(a.get_potential_energy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data in train and test set. \n",
    "# You may adjust the ratio by varying \"test_size\".\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cluster_train, cluster_test, cluster_energy_train, cluster_energy_test = train_test_split(\n",
    "    cluster_trajectory, cluster_energy, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8768a59593973d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The model we use for the total energy is \n",
    "\n",
    "$$E = \\sum_{i<j} {\\mathcal GP}(r_{ij}).$$ \n",
    "\n",
    "To fit the GP, we need to obtain all pair-wise distances in each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.neighborlist import neighbor_list\n",
    "\n",
    "def get_distances(atoms_array,cutoff=3.0):\n",
    "    distances = []\n",
    "    for a in atoms_array:\n",
    "        i, j, d = neighbor_list('ijd', a, cutoff)\n",
    "        d = d[i < j]  # We exclude duplicates\n",
    "        distances.append(d)\n",
    "    return distances # List of list of distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_train = get_distances(cluster_train)\n",
    "distances_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f2ae07101f4f3709",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The target data is the sum of Gaussian Process models. We need to find the covariance of total energies: if the covariance of two pair interactions terms is $k(r,r')$, the covariance of two total energies of two configurations $A$ and $B$ is the sum of covariance functions: \n",
    "\n",
    "$$\\langle E_A E_B \\rangle = \\sum_{ij \\in A, i'j' \\in B} k(r_{ij},r_{i'j'})$$ \n",
    "\n",
    "The following class implements this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class SumGP:\n",
    "    \"\"\"Class implementing a sum Gaussian Process\"\"\"\n",
    "    \n",
    "    def __init__(self, length_scale=1.0, function_range=1.0, error=0.1):\n",
    "        \"\"\"Initialise the class with the GP hyperparameters\"\"\"\n",
    "        self.length_scale = length_scale\n",
    "        self.function_range = function_range\n",
    "        self.error = error\n",
    "\n",
    "    def update_covariance(self):\n",
    "        \"\"\"Update the covariance matrix\"\"\"\n",
    "        self.covariance = self.sum_covariance(self.training_data,self.training_data)\n",
    "        self.covariance += np.eye(len(self.covariance))*self.error**2\n",
    "    \n",
    "    def update_weights(self):\n",
    "        \"\"\"Update the GP model weights\"\"\"\n",
    "        self.weights = np.linalg.solve(self.covariance,self.training_target)\n",
    "        \n",
    "    def update_gp(self):\n",
    "        \"\"\"Update the covariance and the GP model weights\"\"\"\n",
    "        self.update_covariance()\n",
    "        self.update_weights()\n",
    "        \n",
    "    def set_training_data(self,distances,energies):\n",
    "        \"\"\"Add training data and perform the fit\"\"\"\n",
    "        self.training_data = distances\n",
    "        self.training_target = energies\n",
    "        self.update_gp()\n",
    "        \n",
    "    def set_parameters(self,length_scale=None,function_range=None,error=None):\n",
    "        \"\"\"Update GP hyperparameters\"\"\"\n",
    "        changed = False\n",
    "        if length_scale is not None:\n",
    "            self.length_scale = length_scale\n",
    "            changed = True\n",
    "        if function_range is not None:\n",
    "            self.function_range = function_range\n",
    "            changed = True\n",
    "        if error is not None:\n",
    "            self.error = error\n",
    "            changed = True\n",
    "        if changed:\n",
    "            self.update_gp()\n",
    "        \n",
    "    def predict(self,distances, do_variance=False, do_covariance=False):\n",
    "        \"\"\"\n",
    "        Predicts total energy for a set of pairwise distances, \n",
    "        optionally with variances\n",
    "        \"\"\"\n",
    "        k = self.sum_covariance(distances,self.training_data)\n",
    "        mean = np.dot(k,self.weights)\n",
    "        res = {\"mean\":mean}\n",
    "        if do_variance:\n",
    "            variance = []\n",
    "            for _d,_k in zip(distances,k):\n",
    "                variance.append(self.error**2+\n",
    "                    self.sum_covariance([_d],[_d])[0,0] - \n",
    "                           np.dot(_k, np.linalg.solve(self.covariance,_k))\n",
    "                )\n",
    "            res[\"variance\"] = variance\n",
    "        \n",
    "        if do_covariance:\n",
    "            covariance = self.sum_covariance(distances,distances)\n",
    "            res[\"covariance\"] = ( np.eye(len(distances))*self.error**2 + \n",
    "                                 covariance - np.dot(k,np.linalg.solve(self.covariance,k.T)) )\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    def sum_covariance(self, d1, d2):\n",
    "        \"\"\"Sum covariance function\"\"\"\n",
    "        covariance = []\n",
    "        for i, _d1 in enumerate(d1):\n",
    "            _c_row = []\n",
    "            for j, _d2 in enumerate(d2):\n",
    "                distance_matrix = cdist(\n",
    "                    np.array(_d1)[:,None],\n",
    "                    np.array(_d2)[:,None],\n",
    "                    'euclidean')\n",
    "                \n",
    "                _c = np.sum(self.function_range**2*np.exp(\n",
    "                            -0.5*distance_matrix**2/self.length_scale**2))\n",
    "                _c_row.append(_c)\n",
    "            covariance.append(_c_row)\n",
    "        covariance = np.array(covariance)\n",
    "        return covariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb4d8a8eac70c4a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We now use this class to build a Gaussian Process regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the GP with hyperparameters\n",
    "sum_gp = SumGP(length_scale=0.25, error=0.5, function_range=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data and fit the model\n",
    "sum_gp.set_training_data(distances_train,cluster_energy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a9ddec6e2080df2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Optimising the hyperparameters\n",
    "To find the optimal hyperparameters (`length_scale`, `error` and `function_range`) we can try maximising the likelihood of the model: \n",
    "\n",
    "$$\n",
    "\\log L = -\\frac{1}{2} \\mathbf{y}^T \\mathbf{K}^{-1} \\mathbf{y} - \\frac{1}{2} \\log |\\mathbf{K}| - \\frac{n}{2} \\log 2 \\pi$$\n",
    "\n",
    "Remember, the two main components of this expression balance the goodness of the fit (first term) and the complexity of the model (second term).\n",
    "\n",
    "### Question 5.a\n",
    "\n",
    "Implement a log likelihood function for the `SumGP` class using the template provided below. Use the numpy function [np.linalg.slogdet](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.slogdet.html) to compute the log of the determinent of the covariance matrix. For the first term of the log likelihood expression, notice that $\\mathbf{K}^{-1} \\mathbf{y} = \\mathbf{w}$, the fitted weights of the model, stored as `self.weights` in the `SumGP` class. [10 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-09fb5482338e98b8",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_likelihood(self):\n",
    "    \"\"\"Calculate GP likelihood\"\"\"\n",
    "\n",
    "    res = 0.0\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return res\n",
    "\n",
    "SumGP.get_likelihood = get_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.b\n",
    "\n",
    "Compute the log likelihood as a function of the `length_scale` hyperparameter. Plot the results, and determine the optimal parameter, given the other two hyperparameters remain fixed. [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d5bc30f0c6902ed0",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sum_gp = \n",
    "# Add data and fit the model\n",
    "\n",
    "length_scale_array = # np.linspace()\n",
    "likelihood_array = []\n",
    "for _l in length_scale_array:\n",
    "    sum_gp.set_parameters(length_scale=_l)\n",
    "    likelihood_array.append(sum_gp.get_likelihood())\n",
    "    \n",
    "plt.plot()\n",
    "plt.xlabel('Length scale')\n",
    "plt.ylabel('Log likelihood');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77f1a920c0092db4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 6.a\n",
    "\n",
    "Set the `length_scale` hyperparameter to the optimal value you found above, and plot the two-body interatomic potential model as a function of interatomic distances, with error bars, and compare it with the known solution, the Lennard-Jones model. You need to set the range of distances where you want to inspect the model - start from short distances and go beyond the cutoff (3.0) we used. [10 marks]\n",
    "\n",
    "Here is some sample code to do predictions to get you started\n",
    "\n",
    "```python\n",
    "# Predict pair interaction energies using the GP model\n",
    "r_min = ...\n",
    "r_max = ...\n",
    "r_test = np.linspace(r_min,r_max)[:,None]\n",
    "test_gp = sum_gp.predict(r_test,do_variance=True,do_covariance=True)\n",
    "e_test_gp = test_gp[\"mean\"]\n",
    "v_test_gp = test_gp[\"variance\"] \n",
    "c_test_gp = test_gp[\"covariance\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5f19d3acca286b61",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sum_gp.set_parameters(length_scale=)\n",
    "\n",
    "# Lennard-Jones model - the target of the GP model\n",
    "e_test_lj = # function of r_test\n",
    "\n",
    "# Predict pair interaction energies using the GP model\n",
    "test_gp = sum_gp.predict(r_test,do_variance=True,do_covariance=True)\n",
    "e_test_gp = test_gp[\"mean\"]\n",
    "v_test_gp = test_gp[\"variance\"] \n",
    "c_test_gp = test_gp[\"covariance\"]\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(r_test,e_test_lj)\n",
    "plt.errorbar(r_test,e_test_gp,yerr=np.sqrt(v_test_gp))\n",
    "plt.ylim([-1.2,4])\n",
    "plt.xlabel('Distance $r_{ij}$')\n",
    "plt.ylabel('Energy / eV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.b\n",
    "\n",
    "Inspect the predicted error. Identify the domains where the predicted error is large - what is the reason for this? [10 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e742c8decc5b3a46",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c410a5aae7969a0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 6.c\n",
    "\n",
    "In the code cell below, using the `np.random.multivariate_normal` function (as seen in the lecture), with `test_gp[\"mean\"]` as the mean and `test_gp[\"covariance\"]` as the covariance, where `test_gp` is the result of calling `sum_gp.predict()`), draw samples from the posterior. Plot the results together with the known target function (Lennard-Jones pairwise interactions). Looking at these samples, how appropriate is our prior (squared exponential kernel)? Which feature of the Lennard-Jones model is causing problems? [5 marks code + 5 marks discussion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-565f12e6502c715f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N_sample = 5\n",
    "\n",
    "for i in range(N_sample):\n",
    "    s_test_gp = # np.random.multivariate_normal()\n",
    "    plt.plot(r_test, s_test_gp, 'r--')\n",
    "plt.plot(r_test,e_test_lj,\"k-\")\n",
    "plt.ylim([-1.2,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-812b5ff91b18962b",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f026710554e4f666",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Adapt the code used above to predict GP energies (i.e., using `sum_gp.predict()`), evaluate the GP model on the test set `distances_test` we generated by splitting the original data set. Plot the correlation of the target energy and the prediction, with error bars. [5 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-61e8427026eead65",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cluster_gp = sum_gp.predict(distances_test, do_variance=True)\n",
    "cluster_energy_predict = \n",
    "cluster_energy_variance = \n",
    "\n",
    "plt.errorbar(cluster_energy_test, cluster_energy_predict,\n",
    "             yerr=np.sqrt(cluster_energy_variance),fmt=\".\")\n",
    "plt.xlabel('True energy / eV')\n",
    "plt.ylabel('Predicted energy / eV');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21f361e0d3889f8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Extension  question (not assessed)\n",
    "\n",
    "Instead of the squared exponential kernel, implement another kernel (e.g. the exponential kernel $k(r,r') = \\exp ( |r-r'| / l)$ or any other) in the `SumGP` class. Does it represent a better prior than the squared exponential kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5336ac29a70a74b5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
